{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchmetrics\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from torch.utils.data import random_split, DataLoader, Dataset\n",
    "from torchvision.transforms import transforms, Compose\n",
    "import config_model\n",
    "from config_model import target_transforms, QrDBest, early_stopping_callback, check_point_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNet50 = models.resnet50(weights=\"IMAGENET1K_V2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LightningQrDBest(L.LightningDataModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.img_dir = config_model.IMAGE_DIR \n",
    "        \n",
    "        self.train_transforms= Compose(config_model.train_transform_compose)\n",
    "        \n",
    "        self.val_transforms = Compose(config_model.test_transform_compose)\n",
    "        \n",
    "        self.target_transforms = target_transforms\n",
    "        \n",
    "        self.batch_size = config_model.BATCH_SIZE\n",
    "        \n",
    "    def setup(self, stage: str):\n",
    "        if stage == 'fit':\n",
    "            self.full_dataset = QrDBest(self.img_dir)\n",
    "            self.train_size = int( 0.9 * len(self.full_dataset))\n",
    "            self.val_size = len(self.full_dataset) - self.train_size\n",
    "            self.train_dataset, self.val_dataset = random_split(self.full_dataset, [self.train_size, self.val_size],torch.Generator().manual_seed(50))\n",
    "            self.train_dataset.dataset.img_transforms = self.train_transforms\n",
    "            self.train_dataset.dataset.target_transforms = self.target_transforms\n",
    "            self.val_dataset.dataset.img_transforms = self.val_transforms\n",
    "            self.val_dataset.dataset.target_transforms = self.target_transforms\n",
    "            \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=config_model.NUM_WORKERS)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size, shuffle=False, num_workers=config_model.NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Net(L.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.example_input_array = torch.randn(1, 1, 64, 64)\n",
    "        self.model = models.resnet50(weights=\"IMAGENET1K_V2\")\n",
    "        num_classes = 4\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)\n",
    "        self.model.conv1 = nn.Conv2d(\n",
    "        in_channels=1,  # Change input channels to 1 for grayscale images\n",
    "        out_channels=self.model.conv1.out_channels,\n",
    "        kernel_size=self.model.conv1.kernel_size,\n",
    "        stride=self.model.conv1.stride,\n",
    "        padding=self.model.conv1.padding,\n",
    "        bias=self.model.conv1.bias\n",
    "        )\n",
    "        self.loss_function = nn.CrossEntropyLoss()\n",
    "        self.accuracy = torchmetrics.Accuracy('multiclass', num_classes=4)\n",
    "        self.f1_score = torchmetrics.F1Score('multiclass', num_classes=4)\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def _common_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x = x.view(x.size(0), 1, 64, 64)\n",
    "        output = self.forward(x)\n",
    "        loss = self.loss_function(output, y)\n",
    "        preds = torch.argmax(output, dim=1)\n",
    "        return loss, preds, y\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, preds, y = self._common_step(batch, batch_idx)\n",
    "        y = torch.argmax(y, dim=1)\n",
    "        train_accuracy = self.accuracy(preds, y)\n",
    "        train_f1_score = self.f1_score(preds, y)\n",
    "        self.log_dict({'train_loss': loss, 'train_accuracy': train_accuracy, 'train_f1_score': train_f1_score},\n",
    "                      prog_bar=True, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, preds, y = self._common_step(batch, batch_idx)\n",
    "        y = torch.argmax(y, dim=1)\n",
    "        val_accuracy = self.accuracy(preds, y)\n",
    "        val_f1_score = self.f1_score(preds, y)\n",
    "        self.log_dict({\"val_loss\": loss, \"val_accuracy\": val_accuracy, \"val_f1_score\": val_f1_score},\n",
    "                      prog_bar=True, on_epoch=True, on_step=False)\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, scores, y = self._common_step(batch, batch_idx)\n",
    "        self.log('test_loss', loss)\n",
    "        return loss\n",
    "    \n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x = x.view(x.size(0), 1, 64, 64)\n",
    "        scores = self.forward(x)\n",
    "        preds = torch.argmax(scores, dim=1)\n",
    "        return preds\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = LightningQrDBest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/parsa/.local/lib/python3.10/site-packages/lightning/fabric/connector.py:571: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(accelerator=\"gpu\", devices=[0], precision=16, callbacks=[early_stopping_callback, check_point_callback],\n",
    "                    max_epochs=50, min_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type               | Params | Mode  | In sizes       | Out sizes\n",
      "------------------------------------------------------------------------------------------\n",
      "0 | model         | ResNet             | 23.5 M | train | [1, 1, 64, 64] | [1, 4]   \n",
      "1 | loss_function | CrossEntropyLoss   | 0      | train | ?              | ?        \n",
      "2 | accuracy      | MulticlassAccuracy | 0      | train | ?              | ?        \n",
      "3 | f1_score      | MulticlassF1Score  | 0      | train | ?              | ?        \n",
      "------------------------------------------------------------------------------------------\n",
      "23.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.040    Total estimated model params size (MB)\n",
      "154       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 122/122 [00:03<00:00, 31.18it/s, v_num=2, val_loss=0.168, val_accuracy=0.944, val_f1_score=0.944, train_loss=0.489, train_accuracy=0.801, train_f1_score=0.801]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 0.168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 122/122 [00:03<00:00, 34.75it/s, v_num=2, val_loss=0.0799, val_accuracy=0.970, val_f1_score=0.970, train_loss=0.0971, train_accuracy=0.967, train_f1_score=0.967]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.088 >= min_delta = 0.008. New best score: 0.080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 122/122 [00:03<00:00, 34.96it/s, v_num=2, val_loss=0.0357, val_accuracy=0.986, val_f1_score=0.986, train_loss=0.048, train_accuracy=0.986, train_f1_score=0.986] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.044 >= min_delta = 0.008. New best score: 0.036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 122/122 [00:03<00:00, 35.43it/s, v_num=2, val_loss=0.025, val_accuracy=0.991, val_f1_score=0.991, train_loss=0.0655, train_accuracy=0.985, train_f1_score=0.985] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.011 >= min_delta = 0.008. New best score: 0.025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 122/122 [00:03<00:00, 34.77it/s, v_num=2, val_loss=0.0494, val_accuracy=0.986, val_f1_score=0.986, train_loss=0.0185, train_accuracy=0.994, train_f1_score=0.994] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 9 records. Best score: 0.025. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 122/122 [00:03<00:00, 34.74it/s, v_num=2, val_loss=0.0494, val_accuracy=0.986, val_f1_score=0.986, train_loss=0.0185, train_accuracy=0.994, train_f1_score=0.994]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model=model, datamodule=dm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
