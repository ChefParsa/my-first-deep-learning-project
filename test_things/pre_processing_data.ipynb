{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision.transforms import transforms, Compose\n",
    "from torchvision.io import read_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x76f1ce929550>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(57)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pre_process_data(Dataset):\n",
    "    def __init__(self, images_dir, img_transforms=None, target_transforms=None):\n",
    "        self.images_dir = images_dir\n",
    "        self.img_transforms = img_transforms\n",
    "        self.target_transforms = target_transforms\n",
    "        self.img_labels = os.listdir(self.images_dir)\n",
    "        \n",
    "       \n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.images_dir, self.img_labels[idx])\n",
    "        image = read_image(img_path)\n",
    "        image = image.float()\n",
    "        image = image / 255.0\n",
    "        label = self.calculate_label(self.img_labels[idx])\n",
    "        #print(self.img_labels[idx])\n",
    "       \n",
    "        if self.img_transforms:\n",
    "            image = self.img_transforms(image)\n",
    "        if self.target_transforms:\n",
    "            label = self.target_transforms(label)\n",
    "        \n",
    "        return image, label\n",
    "        \n",
    "    def calculate_mean_std(self, dataloader):\n",
    "        mean = 0.0\n",
    "        std = 0.0\n",
    "        total_images_count = 0\n",
    "\n",
    "        for images, _ in dataloader:\n",
    "            batch_samples = images.size(0)  # Number of images in the batch\n",
    "            total_images_count += batch_samples\n",
    "            \n",
    "            images = images.view(batch_samples, images.size(1), -1)  # Flatten the image pixels\n",
    "            mean += images.float().mean(2).sum(0)\n",
    "            std += images.float().std(2).sum(0)\n",
    "\n",
    "        mean /= total_images_count\n",
    "        std /= total_images_count\n",
    "\n",
    "        return mean.item(), std.item()\n",
    "\n",
    "    \n",
    "    def calculate_label(self, img_basename):\n",
    "        tmp = img_basename[:len(img_basename)-4].split(\"_\")\n",
    "        row = tmp[2]\n",
    "        rod_id = int(tmp[3])\n",
    "        if row in {\"A\", \"B\", \"E\", \"F\", \"I\", \"J\"}:\n",
    "            label = 4-(rod_id % 4)\n",
    "        else:\n",
    "            label = (rod_id % 4)+1\n",
    "        return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    #transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset =pre_process_data(images_dir=\"QR_d_best\",img_transforms=dataset_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=32, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6096397638320923\n",
      "0.14037656784057617\n",
      "0.61\n",
      "0.14\n"
     ]
    }
   ],
   "source": [
    "mean, std = dataset.calculate_mean_std(dataloader)\n",
    "print(mean)\n",
    "print(std)\n",
    "mean = round(mean, 3)\n",
    "std = round(std, 3)\n",
    "print(mean)\n",
    "print(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3888\n",
      "432\n"
     ]
    }
   ],
   "source": [
    "train_size = int(0.9 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "print(train_size)\n",
    "print(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    #transforms.ToTensor(),\n",
    "    transforms.RandomHorizontalFlip(),  # Randomly flip images horizontally\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "    transforms.Normalize(mean=[mean], std = [std])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.Normalize(mean=[mean], std=[std])\n",
    "])\n",
    "\n",
    "def target_transform(label):\n",
    "    one_hot = torch.zeros((4))\n",
    "    one_hot[label - 1] = 1.0\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.dataset.img_transforms = train_transform\n",
    "train_dataset.dataset.target_transforms = target_transform\n",
    "test_dataset.dataset.img_transforms = test_transform\n",
    "test_dataset.dataset.target_transforms = target_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432\n",
      "432\n",
      "torch.Size([16, 1, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "image_counter = 0\n",
    "label_counter = 0\n",
    "for images, labels in test_loader:\n",
    "    image_counter += len(images)\n",
    "    label_counter += len(labels)\n",
    "    \n",
    "print(image_counter)\n",
    "print(label_counter)\n",
    "print(images.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.2255, 2.2255, 2.5616,  ..., 1.4132, 1.3291, 1.4412],\n",
      "        [2.2535, 2.2255, 2.5056,  ..., 1.4972, 1.4132, 1.3852],\n",
      "        [2.3095, 2.5056, 2.5336,  ..., 1.2731, 1.5252, 1.4132],\n",
      "        ...,\n",
      "        [1.5252, 1.5812, 1.5252,  ..., 1.4132, 1.4132, 1.4132],\n",
      "        [1.4412, 1.4692, 1.4132,  ..., 1.4412, 1.4412, 1.4132],\n",
      "        [1.4132, 1.4132, 1.3852,  ..., 1.4132, 1.4132, 1.3852]])\n",
      "tensor([0., 0., 0., 1.])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for images, _ in train_loader:\n",
    "    print(images[6][0])\n",
    "    print(_[6])\n",
    "    plt.imshow(images[6][0], cmap=\"gray\")\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda:0\"\n",
    "    print(\"Running on GPU\")\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    print(\"Running on CPU\")\n",
    "    \n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 32, 7)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 5)\n",
    "        self.conv4 = nn.Conv2d(128, 256, 3)\n",
    "        \n",
    "        x = torch.randn((1, 64, 64))\n",
    "        self._to_linear = None\n",
    "        \n",
    "        self.convs(x)\n",
    "        \n",
    "        self.fc1 = nn.Linear(self._to_linear, 256)\n",
    "        self.fc2 = nn.Linear(256, 4)\n",
    "        \n",
    "    def convs(self, X):\n",
    "        X = F.max_pool2d(F.relu(self.conv1(X)), (2, 2))\n",
    "        X = F.max_pool2d(F.relu(self.conv2(X)), (2, 2))\n",
    "        X = F.max_pool2d(F.relu(self.conv3(X)), (2, 2))\n",
    "        X = F.max_pool2d(F.relu(self.conv4(X)), (2, 2))\n",
    "        if self._to_linear is None:\n",
    "            self._to_linear = X.shape[0] * X.shape[1] * X.shape[2]\n",
    "            \n",
    "        return X\n",
    "    \n",
    "    def forward(self, X):\n",
    "        X = self.convs(X)\n",
    "        X = X.view(-1, self._to_linear)\n",
    "        X = F.relu(self.fc1(X))\n",
    "        X = self.fc2(X)\n",
    "        \n",
    "        return X\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_recognition = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(num_recognition.parameters(), lr=0.0001)\n",
    "loss_function  = nn.CrossEntropyLoss()\n",
    "batch_size = 100\n",
    "epochs = 20\n",
    "\n",
    "def train(num_recognition):\n",
    "    for epoch in range(epochs):\n",
    "        for images, labels in tqdm(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            num_recognition.zero_grad()\n",
    "            #optimizer.zero_grad()\n",
    "            output = num_recognition(images)\n",
    "            \n",
    "            loss = loss_function(output, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        print(f\"epoch: {epoch}, loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:00<00:00, 126.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 1.0173938274383545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:00<00:00, 238.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, loss: 0.2836615741252899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:00<00:00, 237.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2, loss: 0.12660667300224304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:00<00:00, 231.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3, loss: 0.16857179999351501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:00<00:00, 235.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4, loss: 0.00910724513232708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:00<00:00, 243.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5, loss: 0.12689617276191711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:00<00:00, 238.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6, loss: 0.10128258168697357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:00<00:00, 231.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7, loss: 0.0164065919816494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:00<00:00, 237.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8, loss: 0.01592325046658516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:00<00:00, 234.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9, loss: 0.012732368893921375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:00<00:00, 234.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10, loss: 0.10715445876121521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:00<00:00, 234.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11, loss: 0.034660451114177704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:00<00:00, 227.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12, loss: 0.0001638564426684752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:00<00:00, 237.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13, loss: 0.0014182113809511065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:00<00:00, 230.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14, loss: 0.00039084706804715097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:00<00:00, 226.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15, loss: 0.0007303052116185427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:00<00:00, 232.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16, loss: 0.00012965218047611415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:00<00:00, 230.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17, loss: 0.03848392888903618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:00<00:00, 235.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18, loss: 2.550193494244013e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:00<00:00, 233.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19, loss: 0.0041120960377156734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(num_recognition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(num_recognition):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(test_loader):\n",
    "            output = num_recognition(images.to(device))\n",
    "            # print(output.shape)\n",
    "            predicted_class = torch.argmax(output, dim=1)\n",
    "            # print(predicted_class)\n",
    "            true_class = torch.argmax(labels.to(device), dim=1)\n",
    "            # print(true_class)\n",
    "            comparision = predicted_class == true_class\n",
    "            count_true = comparision.sum().item()\n",
    "            len_comparision = comparision.numel()\n",
    "            count_false = len_comparision - count_true\n",
    "            total += len_comparision\n",
    "            correct += count_true\n",
    "            # print(count_true)\n",
    "            # print(count_false)\n",
    "            # print(predicted_class == true_class)\n",
    "            # print(comparision.shape)\n",
    "            # print(predicted_class.shape)\n",
    "            # break\n",
    "\n",
    "    print(f\"Accuracy: {round(correct/total, 3)}\")\n",
    "    print(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:00<00:00, 109.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.988\n",
      "427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test(num_recognition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(\"runs/logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(num_recognition):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(test_loader):\n",
    "            output = num_recognition(images.to(device))\n",
    "            # print(output.shape)\n",
    "            predicted_class = torch.argmax(output, dim=1)\n",
    "            # print(predicted_class)\n",
    "            true_class = torch.argmax(labels.to(device), dim=1)\n",
    "            # print(true_class)\n",
    "            comparision = predicted_class == true_class\n",
    "            count_true = comparision.sum().item()\n",
    "            len_comparision = comparision.numel()\n",
    "            count_false = len_comparision - count_true\n",
    "            total += len_comparision\n",
    "            correct += count_true\n",
    "            \n",
    "            accuracy = 100 * correct/ total\n",
    "            writer.add_scalar(\"Test Accuracy\", accuracy)\n",
    "            # print(count_true)\n",
    "            # print(count_false)\n",
    "            # print(predicted_class == true_class)\n",
    "            # print(comparision.shape)\n",
    "            # print(predicted_class.shape)\n",
    "            # break\n",
    "\n",
    "    print(f\"Accuracy: {round(correct/total, 3)}\")\n",
    "    print(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/14 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:00<00:00, 99.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.988\n",
      "427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test(num_recognition)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class earlyStopping():\n",
    "#     def __init__(self, patience = 5, min_delta = 0.1):\n",
    "#         self.patience = patience\n",
    "#         self.min_delta = min_delta\n",
    "#         self.patience_conter = 0\n",
    "#         self.min_validation_loss = float('inf')\n",
    "#     def __call__(self, validation_loss):\n",
    "#         if validation_loss < self.min_validation_loss:\n",
    "#             self.min_validation_loss = validation_loss\n",
    "#             self.patience_conter = 0\n",
    "#         elif validation_loss - self.min_validation_loss > self.min_delta:\n",
    "#             self.patience_conter += 1\n",
    "#             if self.patience_conter >= self.patience:\n",
    "#                 return True\n",
    "#         return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping():\n",
    "    def __init__(self, patience = 3, min_delta = 0.01):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.patience_counter = 0\n",
    "    def early_stop(self, validation_loss, train_loss):\n",
    "        if (validation_loss - train_loss) > self.min_delta:\n",
    "            self.patience_counter += 1\n",
    "            if self.patience_counter >= self.patience:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=3, min_delta=0.0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.patience_counter = 0\n",
    "        self.best_validation_loss = float('inf')\n",
    "    \n",
    "    def early_stop(self, validation_loss):\n",
    "        # Check if validation loss has improved sufficiently\n",
    "        if validation_loss < self.best_validation_loss - self.min_delta:\n",
    "            self.best_validation_loss = validation_loss\n",
    "            self.patience_counter = 0  # Reset the counter if there is an improvement\n",
    "        else:\n",
    "            self.patience_counter += 1  # No improvement\n",
    "            if self.patience_counter >= self.patience:\n",
    "                return True  # Stop training if patience has been exhausted\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "EarlyStopping.early_stop() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m t \u001b[38;5;241m=\u001b[39m EarlyStopping()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_stop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.0270\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0001\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m t\u001b[38;5;241m.\u001b[39mearly_stop(\u001b[38;5;241m0.0253\u001b[39m, \u001b[38;5;241m0.0001\u001b[39m)\n\u001b[1;32m      4\u001b[0m t\u001b[38;5;241m.\u001b[39mearly_stop(\u001b[38;5;241m0.0309\u001b[39m, \u001b[38;5;241m0.0001\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: EarlyStopping.early_stop() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "t = EarlyStopping()\n",
    "t.early_stop(0.0270, 0.0001)\n",
    "t.early_stop(0.0253, 0.0001)\n",
    "t.early_stop(0.0309, 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping1():\n",
    "    def __init__(self, patience=3, min_delta=0.00):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.patience_counter = 0\n",
    "        self.best_loss = None\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = validation_loss\n",
    "        elif validation_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = validation_loss\n",
    "            self.patience_counter = 0\n",
    "        else:\n",
    "            self.patience_counter += 1\n",
    "            if self.patience_counter >= self.patience:\n",
    "                return True\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(output, labels):\n",
    "    predicted_class = torch.argmax(output, dim=1)\n",
    "    true_class = torch.argmax(labels, dim=1)\n",
    "    comparision = predicted_class == true_class\n",
    "    count_true = comparision.sum().item()\n",
    "    total_train = comparision.numel()\n",
    "    \n",
    "    accuracy = round(count_true / total_train, 3)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(num_recognition.parameters(), lr=0.0001)\n",
    "loss_function  = nn.CrossEntropyLoss()\n",
    "batch_size = 100\n",
    "epochs = 50\n",
    "earlystopper = EarlyStopping1(patience=10, min_delta=0.008)\n",
    "def train(num_recognition):\n",
    "    best_accuracy = -1\n",
    "    for epoch in range(epochs):\n",
    "        num_recognition.train()\n",
    "        train_running_accuracy = 0\n",
    "        train_running_loss = 0\n",
    "        \n",
    "        for train_images, train_labels in train_loader:\n",
    "            \n",
    "            train_images, train_labels = train_images.to(device), train_labels.to(device)\n",
    "            \n",
    "            num_recognition.zero_grad()\n",
    "            #optimizer.zero_grad()\n",
    "            output = num_recognition(train_images)\n",
    "            \n",
    "            loss = loss_function(output, train_labels)\n",
    "            train_running_loss += loss.item()\n",
    "            train_running_accuracy += calculate_accuracy(output, train_labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Average loss and accuracy\n",
    "        train_loss = train_running_loss / len(train_loader)\n",
    "        train_accuracy = train_running_accuracy / len(train_loader)\n",
    "        \n",
    "        # Log training metrics\n",
    "        writer.add_scalar('Training Loss', train_loss, epoch)\n",
    "        writer.add_scalar('Training Accuracy', train_accuracy, epoch)\n",
    "        \n",
    "        #print(f\"epoch: {epoch}, loss: {loss}\")\n",
    "        \n",
    "        # Evaluate on the test set\n",
    "        num_recognition.eval()\n",
    "        test_running_loss = 0.0\n",
    "        test_running_accuracy = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for test_images, test_labels in test_loader:\n",
    "                test_images, test_labels = test_images.to(device), test_labels.to(device)\n",
    "                outputs = num_recognition(test_images)\n",
    "                loss = loss_function(outputs, test_labels)\n",
    "                test_running_loss += loss.item()\n",
    "                test_running_accuracy += calculate_accuracy(outputs, test_labels)\n",
    "\n",
    "        # Average loss and accuracy\n",
    "        test_loss = test_running_loss / len(test_loader)\n",
    "        test_accuracy = test_running_accuracy / len(test_loader)\n",
    "\n",
    "        # Log test metrics\n",
    "        writer.add_scalar('Test Loss', test_loss, epoch)\n",
    "        writer.add_scalar('Test Accuracy', test_accuracy, epoch)\n",
    "        \n",
    "        print(f'Epoch [{epoch + 1}/{epochs}], '\n",
    "              f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, '\n",
    "              f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')\n",
    "        \n",
    "        if test_accuracy > best_accuracy:\n",
    "            best_accuracy = test_accuracy\n",
    "            torch.save(num_recognition, \"best_model.pth\")\n",
    "            print(f\"beast accuracy till now is : {best_accuracy}\")\n",
    "        \n",
    "        if earlystopper.early_stop(test_loss):\n",
    "            print(f\"early stop at epoch: {epoch + 1}\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_recognition = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Train Loss: 0.0205, Train Accuracy: 0.9934, Test Loss: 0.0987, Test Accuracy: 0.9779\n",
      "beast accuracy till now is : 0.9778571428571429\n",
      "Epoch [2/50], Train Loss: 0.0108, Train Accuracy: 0.9972, Test Loss: 0.0283, Test Accuracy: 0.9911\n",
      "beast accuracy till now is : 0.9911428571428571\n",
      "Epoch [3/50], Train Loss: 0.0025, Train Accuracy: 1.0000, Test Loss: 0.0224, Test Accuracy: 0.9911\n",
      "Epoch [4/50], Train Loss: 0.0015, Train Accuracy: 1.0000, Test Loss: 0.0186, Test Accuracy: 0.9911\n",
      "Epoch [5/50], Train Loss: 0.0011, Train Accuracy: 1.0000, Test Loss: 0.0190, Test Accuracy: 0.9956\n",
      "beast accuracy till now is : 0.9955714285714287\n",
      "Epoch [6/50], Train Loss: 0.0008, Train Accuracy: 1.0000, Test Loss: 0.0197, Test Accuracy: 0.9889\n",
      "Epoch [7/50], Train Loss: 0.0006, Train Accuracy: 1.0000, Test Loss: 0.0152, Test Accuracy: 0.9956\n",
      "Epoch [8/50], Train Loss: 0.0005, Train Accuracy: 1.0000, Test Loss: 0.0173, Test Accuracy: 0.9956\n",
      "Epoch [9/50], Train Loss: 0.0004, Train Accuracy: 1.0000, Test Loss: 0.0224, Test Accuracy: 0.9934\n",
      "Epoch [10/50], Train Loss: 0.0004, Train Accuracy: 1.0000, Test Loss: 0.0145, Test Accuracy: 0.9956\n",
      "Epoch [11/50], Train Loss: 0.0003, Train Accuracy: 1.0000, Test Loss: 0.0165, Test Accuracy: 0.9911\n",
      "Epoch [12/50], Train Loss: 0.0002, Train Accuracy: 1.0000, Test Loss: 0.0152, Test Accuracy: 0.9956\n",
      "Epoch [13/50], Train Loss: 0.0002, Train Accuracy: 1.0000, Test Loss: 0.0163, Test Accuracy: 0.9956\n",
      "Epoch [14/50], Train Loss: 0.0002, Train Accuracy: 1.0000, Test Loss: 0.0147, Test Accuracy: 0.9956\n",
      "early stop at epoch: 14\n"
     ]
    }
   ],
   "source": [
    "#num_recognition = Net().to(device)\n",
    "\n",
    "train(num_recognition)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: {'TP': 97, 'FP': 0, 'FN': 2}, 2: {'TP': 113, 'FP': 0, 'FN': 0}, 3: {'TP': 111, 'FP': 0, 'FN': 0}, 4: {'TP': 109, 'FP': 2, 'FN': 0}}\n"
     ]
    }
   ],
   "source": [
    "metrics = {\n",
    "    1:{\"TP\":0, \"FP\":0, \"FN\":0}, \n",
    "    2:{\"TP\":0, \"FP\":0, \"FN\":0}, \n",
    "    3:{\"TP\":0, \"FP\":0, \"FN\":0}, \n",
    "    4:{\"TP\":0, \"FP\":0, \"FN\":0}\n",
    "}\n",
    "\n",
    "batch_size = 100\n",
    "correct = 0\n",
    "\n",
    "confusion_matrix = [[0 for i in range(4)] for j in range(4)]\n",
    "\n",
    "with torch.no_grad():\n",
    "    for test_images, test_labels in test_loader:\n",
    "        test_images, test_labels = test_images.to(device), test_labels.to(device)\n",
    "        output = num_recognition(test_images)\n",
    "        predicted = torch.argmax(output, dim=1)\n",
    "        true_label = torch.argmax(test_labels, dim=1)\n",
    "        comparision = predicted == true_label\n",
    "        for i in range(len(comparision)):\n",
    "            if comparision[i]:\n",
    "                correct += 1\n",
    "                metrics[int(predicted[i])+1][\"TP\"] += 1\n",
    "                confusion_matrix[true_label[i]][predicted[i]] += 1\n",
    "            else:\n",
    "                metrics[int(predicted[i])+1][\"FP\"] += 1\n",
    "                metrics[int(true_label[i])+1][\"FN\"] += 1\n",
    "                confusion_matrix[true_label[i]][predicted[i]] += 1\n",
    "\n",
    "                \n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[97, 0, 0, 2], [0, 113, 0, 0], [0, 0, 111, 0], [0, 0, 0, 109]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6345/2770099397.py:12: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_xticklabels([''] + ['pred1', 'pred2', 'pred3', 'pred4'])\n",
      "/tmp/ipykernel_6345/2770099397.py:13: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_yticklabels([''] + list(metrics.keys()))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert the list to a numpy array\n",
    "# confusion_matrix = np.array(confusion_matrix)\n",
    "\n",
    "# Plotting the confusion matrix\n",
    "fig, ax = plt.subplots()\n",
    "cax = ax.matshow(confusion_matrix, cmap=plt.cm.Blues)\n",
    "\n",
    "# Adding color bar\n",
    "plt.colorbar(cax)\n",
    "\n",
    "# Setting labels for axes\n",
    "ax.set_xticklabels([''] + ['pred1', 'pred2', 'pred3', 'pred4'])\n",
    "ax.set_yticklabels([''] + list(metrics.keys()))\n",
    "\n",
    "# Adding text annotations\n",
    "for i in range(len(confusion_matrix)):\n",
    "    for j in range(len(confusion_matrix[i])):\n",
    "        plt.text(j, i, str(confusion_matrix[i][j]), va='center', ha='center')\n",
    "\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "buf = io.BytesIO()\n",
    "plt.savefig(buf, format='png')\n",
    "buf.seek(0)\n",
    "plt.close()\n",
    "image = Image.open(buf)\n",
    "image = image.convert(\"RGB\")\n",
    "image = np.array(image)\n",
    "\n",
    "image_tensor = torch.tensor(image).permute(2, 0, 1)  # Convert to CxHxW format\n",
    "\n",
    "# Step 3: Log the image to TensorBoard\n",
    "writer = SummaryWriter('runs/matplotlib_example')\n",
    "\n",
    "# Add the image to TensorBoard\n",
    "writer.add_image('Sine_Wave_Plot', image_tensor)\n",
    "\n",
    "# Close the writer\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "buf = io.BytesIO()\n",
    "plt.savefig(buf, format='png')\n",
    "buf.seek(0)\n",
    "image = Image.open(buf)\n",
    "image = image.convert(\"RGB\")\n",
    "image = np.array(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "size of input tensor and input format are different.         tensor shape: (480, 640), input_format: CHW",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m writer \u001b[38;5;241m=\u001b[39m SummaryWriter(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mruns/matplotlib_example\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Add the image to TensorBoard\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_image\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSine_Wave_Plot\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_tensor\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Close the writer\u001b[39;00m\n\u001b[1;32m     10\u001b[0m writer\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/tensorboard/writer.py:656\u001b[0m, in \u001b[0;36mSummaryWriter.add_image\u001b[0;34m(self, tag, img_tensor, global_step, walltime, dataformats)\u001b[0m\n\u001b[1;32m    652\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcaffe2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m workspace\n\u001b[1;32m    654\u001b[0m     img_tensor \u001b[38;5;241m=\u001b[39m workspace\u001b[38;5;241m.\u001b[39mFetchBlob(img_tensor)\n\u001b[1;32m    655\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_file_writer()\u001b[38;5;241m.\u001b[39madd_summary(\n\u001b[0;32m--> 656\u001b[0m     \u001b[43mimage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataformats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataformats\u001b[49m\u001b[43m)\u001b[49m, global_step, walltime\n\u001b[1;32m    657\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/tensorboard/summary.py:570\u001b[0m, in \u001b[0;36mimage\u001b[0;34m(tag, tensor, rescale, dataformats)\u001b[0m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Output a `Summary` protocol buffer with images.\u001b[39;00m\n\u001b[1;32m    544\u001b[0m \n\u001b[1;32m    545\u001b[0m \u001b[38;5;124;03mThe summary has up to `max_images` summary values containing images. The\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;124;03m  buffer.\u001b[39;00m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    569\u001b[0m tensor \u001b[38;5;241m=\u001b[39m make_np(tensor)\n\u001b[0;32m--> 570\u001b[0m tensor \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_HWC\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataformats\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;66;03m# Do not assume that user passes in values in [0, 255], use data type to detect\u001b[39;00m\n\u001b[1;32m    572\u001b[0m scale_factor \u001b[38;5;241m=\u001b[39m _calc_scale_factor(tensor)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/tensorboard/_utils.py:102\u001b[0m, in \u001b[0;36mconvert_to_HWC\u001b[0;34m(tensor, input_format)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_to_HWC\u001b[39m(tensor, input_format):  \u001b[38;5;66;03m# tensor: numpy array\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(input_format)) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\n\u001b[1;32m    100\u001b[0m         input_format\n\u001b[1;32m    101\u001b[0m     ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can not use the same dimension shordhand twice.         input_format: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_format\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 102\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tensor\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\n\u001b[1;32m    103\u001b[0m         input_format\n\u001b[1;32m    104\u001b[0m     ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize of input tensor and input format are different. \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;124m        tensor shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtensor\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, input_format: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_format\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    106\u001b[0m     input_format \u001b[38;5;241m=\u001b[39m input_format\u001b[38;5;241m.\u001b[39mupper()\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(input_format) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m:\n",
      "\u001b[0;31mAssertionError\u001b[0m: size of input tensor and input format are different.         tensor shape: (480, 640), input_format: CHW"
     ]
    }
   ],
   "source": [
    "image_tensor = torch.tensor(image).permute(2, 0, 1)  # Convert to CxHxW format\n",
    "\n",
    "# Step 3: Log the image to TensorBoard\n",
    "writer = SummaryWriter('runs/matplotlib_example')\n",
    "\n",
    "# Add the image to TensorBoard\n",
    "writer.add_image('Sine_Wave_Plot', image_tensor)\n",
    "\n",
    "# Close the writer\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
